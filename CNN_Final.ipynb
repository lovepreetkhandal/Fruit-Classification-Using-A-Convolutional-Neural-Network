{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutional Neural Network - Fruit Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Import required packages\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d354ca04df99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuners\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHyperParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Set Up flow For Training & Validation data\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data flow parameters\n",
    "training_data_dir = 'data/training'\n",
    "validation_data_dir = 'data/validation'\n",
    "batch_size= 32\n",
    "image_width =128\n",
    "image_height =128\n",
    "num_channels = 3\n",
    "num_classes =6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generators (adding image augmentation only to training dataset)\n",
    "training_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                                       rotation_range =20,\n",
    "                                       width_shift_range = 0.2,\n",
    "                                       height_shift_range = 0.2,\n",
    "                                       zoom_range =0.2,\n",
    "                                       horizontal_flip =True,\n",
    "                                       brightness_range = (0.5, 1.5),\n",
    "                                       fill_mode = 'nearest')\n",
    "\n",
    "validation_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image flows\n",
    "training_set = training_generator.flow_from_directory(directory = training_data_dir,\n",
    "                                                     target_size = (image_width, image_height),\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     class_mode = 'categorical')\n",
    "validation_set = validation_generator.flow_from_directory(directory = validation_data_dir,\n",
    "                                                     target_size = (image_width, image_height),\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     class_mode = 'categorical')\n",
    "# class mode would be binary if we had only two classes of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Network Architecture\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture (hyperparameter Random Search to find the best model)\n",
    "##def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters =hp.Int(\"input_conv_filters\", min_value =32, max_value =256, step = 32),\n",
    "                    kernel_size = (3,3),\n",
    "                    padding = 'same',\n",
    "                    input_shape = (image_width, image_height, num_channels)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    for i in range(hp.Int(\"n_Conv_Layers\", min_value = 1, max_value = 5, step = 1)):\n",
    "        model.add(Conv2D(filters =hp.Int(f\"Conv{i}_filters\", min_value =32, max_value =256, step = 32), kernel_size = (3,3),padding = 'same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D())\n",
    "        \n",
    "    model.add(Flatten())\n",
    "\n",
    "    for j in range(hp.Int(\"n_Dense_Layers\",min_value =1, max_value =4, step = 1)):\n",
    "        model.add(Dense(hp.Int(f\"Dense_{j}_Neurons\", min_value =32, max_value =256, step = 32)))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "                               \n",
    "        if hp.Boolean(\"Dropout\"):\n",
    "            model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss= 'categorical_crossentropy',\n",
    "                 optimizer = hp.Choice ('optimizer', values = ['adam','RMSProp']),\n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tuner = RandomSearch(hypermodel = build_model,\n",
    "                    objective = 'val_accuracy',\n",
    "                    max_trials = 5,\n",
    "                    executions_per_trial = 5,\n",
    "                    directory = os.path.normpath('C:/'),\n",
    "                    project_name = 'fruit_CNN',\n",
    "                    overwrite = True)\n",
    "\n",
    "### tuner.search(x = training_set, \n",
    "            validation_data = validation_set,\n",
    "            epochs = 100,\n",
    "            batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view artitecture\n",
    "## tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best network\n",
    "### tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summary of best network\n",
    "### tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters =96,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'same',\n",
    "                input_shape = (image_width, image_height, num_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters =192,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters =160,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(filters =160,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(192))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss= 'categorical_crossentropy',\n",
    "             optimizer ='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Train Our Network!\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "num_epochs = 100\n",
    "model_filename = 'models/fruits_CNN_V05.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "save_best_model = ModelCheckpoint(filepath = model_filename,\n",
    "                                 monitor = 'val_accuracy',\n",
    "                                 mode = 'max',\n",
    "                                 verbose =1,\n",
    "                                 save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "history = model.fit(x = training_set,\n",
    "                   validation_data = validation_set,\n",
    "                   batch_size = batch_size,\n",
    "                   epochs = num_epochs,\n",
    "                   callbacks = [save_best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Visualise Training & Validation Performance\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot validation results\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15,15))\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Training Loss\")\n",
    "ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best epoch performance for validation accuracy\n",
    "max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Make Predictions On New Data (Test Set)\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for prediction\n",
    "model_filename = 'models/fruits_CNN_V05.h5'\n",
    "image_width =128\n",
    "image_height =128\n",
    "labels_list = ['apple', 'avocado', 'banana', 'kiwi', 'lemon', 'orange']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pre-processing function\n",
    "\n",
    "def preprocess_image(filepath):\n",
    "    image =load_img(filepath,target_size = (image_width,image_height))\n",
    "\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis =0)\n",
    "    image = image * (1./255)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# image prediction function\n",
    "\n",
    "def make_prediction(image):\n",
    "    class_probs = model.predict(image)\n",
    "    predicted_class = np.argmax(class_probs)\n",
    "\n",
    "    predicted_label =labels_list[predicted_class]\n",
    "    predicted_prob = class_probs[0][predicted_class]\n",
    "    \n",
    "    return predicted_label, predicted_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through test data\n",
    "\n",
    "source_dir ='data/test/'\n",
    "folder_names =  ['apple', 'avocado', 'banana', 'kiwi', 'lemon', 'orange']\n",
    "actual_labels = []\n",
    "predicted_labels = []\n",
    "predicted_probabilities = []\n",
    "filenames =[]\n",
    "\n",
    "for folder in folder_names:\n",
    "    \n",
    "    images = listdir(source_dir + '/' + folder)\n",
    "    \n",
    "    for image in images:\n",
    "        \n",
    "        processed_image = preprocess_image(source_dir + '/'+ folder + '/' + image)\n",
    "        predicted_label, predicted_probability = make_prediction(processed_image)\n",
    "        \n",
    "        actual_labels.append(folder)\n",
    "        predicted_labels.append(predicted_label)\n",
    "        predicted_probabilities.append(predicted_probability)\n",
    "        filenames.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe to analyse\n",
    "prediction_df = pd.DataFrame({\"actual_label\": actual_labels,\n",
    "                             \"predicted_label\": predicted_labels,\n",
    "                             \"predicted_probability\": predicted_probabilities,\n",
    "                             \"filename\": filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df['correct'] = np.where(prediction_df['actual_label']== prediction_df['predicted_label'], 1, 0)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall test set accuracy\n",
    "\n",
    "test_set_accuracy = prediction_df['correct'].sum() / len(prediction_df)\n",
    "print(test_set_accuracy)\n",
    "## 68 % basic\n",
    "## 0.88 % dropout\n",
    "## 93 % augmentation & dropout\n",
    "## hp 100 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix =pd.crosstab(prediction_df['predicted_label'], prediction_df['actual_label'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### percentage (conf_matrix)\n",
    "confusion_matrix =pd.crosstab(prediction_df['predicted_label'], prediction_df['actual_label'], normalize = 'columns')\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
